{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Changed Transfer learning VGG16_IDG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Masfiqur-Mim/Auto_Color/blob/master/Changed_Transfer_learning_VGG16_IDG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioLHdQH3qb5Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "8443c5c9-7497-43d9-99cc-f3fa99fbdcdb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hu3UPair35al",
        "colab_type": "text"
      },
      "source": [
        "CopyData.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6epKpgL2V8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r '/content/drive/My Drive/Dataset' '/content/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew_XMV-S6O-s",
        "colab_type": "text"
      },
      "source": [
        "#Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR4aO-mTrJqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.backend as K\n",
        "from keras.engine import Layer\n",
        "from keras.layers import Conv2D, Conv3D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate\n",
        "from keras.layers import Activation, Dense, Dropout, Flatten\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import TensorBoard, ReduceLROnPlateau\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imsave\n",
        "\n",
        "from time import time\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from PIL import Image, ImageFile\n",
        "#print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asIUhjVQKFdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "IMG_SIZE = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlhyzyoP4h9c",
        "colab_type": "text"
      },
      "source": [
        "Datagen.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNxtI4n1ojXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import keras\n",
        " \n",
        "class ImageDataGenerator(keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, list_files, dim, batch_size=64, shuffle=True):\n",
        "        'Initialization'\n",
        "        \n",
        "        self.list_files = list_files\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_files) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        list_files_batch = [self.list_files[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_files_batch)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_files))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def normalize_batch(self, imgs):\n",
        "        imgs = np.array(imgs, dtype=np.float32)\n",
        "        imgs /= 255\n",
        "        return imgs\n",
        "                                                            \n",
        "    def denormalize_batch(self, imgs, should_clip=True):\n",
        "        #imgs= imgs * self.std + self.mean \n",
        "        if should_clip:\n",
        "            imgs = np.clip(imgs,0,1)\n",
        "        imgs *= 255\n",
        "        return imgs\n",
        "\n",
        "    def __data_generation(self, list_files_batch):\n",
        "        'Generates data containing batch_size samples' \n",
        "        X = []\n",
        "        Y = []\n",
        "        for i, fname in enumerate(list_files_batch):\n",
        "            img = cv2.imread(fname)\n",
        "            img = cv2.resize(img, (self.dim[1], self.dim[0]))\n",
        "            # print(img.shape)\n",
        "            X.append(img)\n",
        "        X = self.normalize_batch(X)\n",
        "        lab_batch = rgb2lab(X)\n",
        "        X_batch = lab_batch[:,:,:,0]     \n",
        "        X_batch = gray2rgb(X_batch)      \n",
        "        X_batch = X_batch.reshape((-1,IMG_SIZE,IMG_SIZE,3)) \n",
        "        \n",
        "        Y_batch = lab_batch[:,:,:,1:] / 128 \n",
        "        \n",
        "        return X_batch, Y_batch\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n651gQG240wz",
        "colab_type": "text"
      },
      "source": [
        "Model.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0POtEFWbfDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SIZE =64\n",
        "import keras,os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten, Input\n",
        "\n",
        "def model_creation(IMG_SIZE, batch_size):\n",
        "\n",
        "    input_layer= Input(shape=(IMG_SIZE, IMG_SIZE, 3,))\n",
        "\n",
        "    newmodel = Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\")(input_layer)\n",
        "    newmodel = Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\")(newmodel)\n",
        "    newmodel = MaxPool2D(pool_size=(2,2),strides=(2,2))(newmodel)\n",
        "    newmodel = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(newmodel)\n",
        "    newmodel = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(newmodel)\n",
        "    newmodel = MaxPool2D(pool_size=(2,2),strides=(2,2))(newmodel)\n",
        "    newmodel = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(newmodel)\n",
        "    newmodel = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(newmodel)\n",
        "    newmodel = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(newmodel)\n",
        "    newmodel = MaxPool2D(pool_size=(2,2),strides=(2,2))(newmodel)\n",
        "    newmodel = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(newmodel)\n",
        "    newmodel = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(newmodel)\n",
        "    newmodel = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(newmodel)\n",
        "    newmodel = MaxPool2D(pool_size=(2,2),strides=(2,2))(newmodel)\n",
        "    newmodel = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(newmodel)\n",
        "    newmodel = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(newmodel)\n",
        "    newmodel = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(newmodel)\n",
        "    newmodel = MaxPool2D(pool_size=(2,2),strides=(2,2))(newmodel)\n",
        "\n",
        "    #newmodel.summary()\n",
        "\n",
        "    #Encoder\n",
        "    #encoder_input = Input(shape=(7, 7, 512,)) #Wrong concept\n",
        "\n",
        "\n",
        "    #Decoder\n",
        "    decoder_output = Conv2D(256, (3,3),  padding='same')(newmodel)\n",
        "    decoder_output = BatchNormalization(epsilon=1e-05, momentum=0.9)(decoder_output)\n",
        "    decoder_output = Activation('relu')(decoder_output)\n",
        "\n",
        "    decoder_output = Conv2D(128, (3,3),  padding='same')(decoder_output)\n",
        "    decoder_output = BatchNormalization(epsilon=1e-05, momentum=0.9)(decoder_output)\n",
        "    decoder_output = Activation('relu')(decoder_output)\n",
        "    decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "\n",
        "    decoder_output = Conv2D(64, (3,3), padding='same')(decoder_output)\n",
        "    decoder_output = BatchNormalization(epsilon=1e-05, momentum=0.9)(decoder_output)\n",
        "    decoder_output = Activation('relu')(decoder_output)\n",
        "    decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "\n",
        "    decoder_output = Conv2D(32, (3,3), padding='same')(decoder_output)\n",
        "    decoder_output = BatchNormalization(epsilon=1e-05, momentum=0.9)(decoder_output)\n",
        "    decoder_output = Activation('relu')(decoder_output)\n",
        "    decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "\n",
        "    decoder_output = Conv2D(16, (3,3), padding='same')(decoder_output)\n",
        "    decoder_output = BatchNormalization(epsilon=1e-05, momentum=0.9)(decoder_output)\n",
        "    decoder_output = Activation('tanh')(decoder_output)\n",
        "    decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "\n",
        "    decoder_output = Conv2D(2, (3, 3), padding='same')(decoder_output)\n",
        "    decoder_output = BatchNormalization(epsilon=1e-05, momentum=0.9)(decoder_output)\n",
        "    decoder_output = Activation('tanh')(decoder_output)\n",
        "    decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "    model = Model(inputs=input_layer, outputs=decoder_output)\n",
        "\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFYSBmzzZuB1",
        "colab_type": "text"
      },
      "source": [
        "##New Default (From Tensorflow Library) Pure Custom DSSIM loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3CTt99iZtXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DSSIMLoss(y_true, y_pred):\n",
        "  return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kmHTw5F7CiT",
        "colab_type": "text"
      },
      "source": [
        "compile.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehpjjh7766Kj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "207674a4-845b-4c0e-ce9c-00ac3d4086b4"
      },
      "source": [
        "model= model_creation(IMG_SIZE, batch_size)\n",
        "opt = keras.optimizers.Adam(learning_rate=0.003)\n",
        "murad_optimizer=RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "#model.compile(optimizer='adam', loss=our_loss_dssim, metrics=[our_eval_ssim]) \n",
        "model.compile(optimizer=murad_optimizer,loss=DSSIMLoss, metrics=['mean_squared_error','accuracy']) #New (29/08/2020)\n",
        "#model.compile(optimizer=opt, loss='mse', metrics=['mean_squared_error']) #MSE d,a:lr=0.007;min loss=0.0074 #MSE b,c:lr=0.003 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 64, 64, 64)        1792      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 64, 64, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 32, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 16, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 8, 8, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 2, 2, 256)         1179904   \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 2, 2, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 2, 2, 128)         295040    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 2, 2, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d (UpSampling2D) (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 4, 4, 64)          73792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 4, 4, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 8, 8, 32)          18464     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 8, 8, 32)          128       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 16, 16, 16)        4624      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 16, 16, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2 (None, 32, 32, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 32, 32, 2)         290       \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 32, 32, 2)         8         \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 32, 32, 2)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2 (None, 64, 64, 2)         0         \n",
            "=================================================================\n",
            "Total params: 16,288,794\n",
            "Trainable params: 16,287,798\n",
            "Non-trainable params: 996\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtV9cAno5L2r",
        "colab_type": "text"
      },
      "source": [
        "train.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNIk0ZJn0Yr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_files = []\n",
        "list_file_pattern = [\"Dataset/Train/*.jpg\"]\n",
        "for file_pattern in list_file_pattern:\n",
        "    sub_list_files = glob.glob(file_pattern)\n",
        "    list_files = [*list_files, *sub_list_files]\n",
        "\n",
        "\n",
        "random.seed(10)\n",
        "random.shuffle(list_files)\n",
        "\n",
        "N_TEST_SAMPLES = int(0.1 * len(list_files))\n",
        "N_TRAIN_SAMPLES= len(list_files) - N_TEST_SAMPLES\n",
        "list_files_train, list_files_val = list_files[:N_TRAIN_SAMPLES], list_files[N_TRAIN_SAMPLES:]\n",
        "\n",
        "print(\"Total number of image:\", len(list_files))\n",
        "print(\"Total number of training:\", N_TRAIN_SAMPLES)\n",
        "print(\"Total number of testing:\", N_TEST_SAMPLES)\n",
        "\n",
        "\n",
        "params = {\n",
        "    'dim': (IMG_SIZE, IMG_SIZE, 3),\n",
        "    #'std': np.array([0.229, 0.224, 0.225]),\n",
        "    #'mean': np.array([0.485, 0.456, 0.406]),\n",
        "    'batch_size': batch_size\n",
        "}\n",
        "\n",
        "# Generators\n",
        "training_generator = ImageDataGenerator(list_files_train, **params, shuffle=True)\n",
        "validation_generator = ImageDataGenerator(list_files_val, **params, shuffle=True)\n",
        "\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=\"output/first_run\")\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, factor=0.5, min_lr=0.000001)\n",
        "callback_list=[tensorboard, learning_rate_reduction]\n",
        "\n",
        "\n",
        "model.fit_generator(\n",
        "        training_generator,\n",
        "        steps_per_epoch=min(N_TRAIN_SAMPLES // batch_size, 500),\n",
        "        initial_epoch=0,\n",
        "        epochs=100,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=min(N_TEST_SAMPLES // batch_size, 50),\n",
        "        callbacks=callback_list,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "#model save\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZnt0dm9sNrb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load model\n",
        "\n",
        "from keras.models import model_from_json\n",
        "\n",
        "# Model reconstruction from JSON file\n",
        "with open('model.json', 'r') as f:\n",
        "    model = model_from_json(f.read())\n",
        "\n",
        "# Load weights into the new model\n",
        "model.load_weights('model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FnrHZzDsWnD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4b76fd43-e480-4a34-bdec-fd6382d18ea8"
      },
      "source": [
        "# Test images\n",
        "test_list=[]\n",
        "for filename in os.listdir('/content/drive/My Drive/Dataset/Test/'):\n",
        "    test_list.append(img_to_array(load_img('/content/drive/My Drive/Dataset/Test/'+ filename, target_size=(IMG_SIZE, IMG_SIZE))))\n",
        "\n",
        "test_list = np.array(test_list, dtype=float)\n",
        "Xtest = rgb2lab(1.0/255*test_list)[:,:,:,0]\n",
        "Xtest = Xtest.reshape(Xtest.shape+(1,)) ####why this???\n",
        "Ytest = rgb2lab(1.0/255*test_list)[:,:,:,1:]\n",
        "Ytest = Ytest / 128\n",
        "print(model.evaluate(Xtest, Ytest, batch_size=batch_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "141/141 [==============================] - 37s 261ms/step\n",
            "0.005860841465644961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVOI7Jcpsfdb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = 0\n",
        "\n",
        "for filename in os.listdir('/content/drive/My Drive/Dataset/Test/'):\n",
        "    test = img_to_array(load_img('/content/drive/My Drive/Dataset/Test/'+filename, target_size=(IMG_SIZE, IMG_SIZE)) )\n",
        "    test*= 1.0/255\n",
        "    lab = rgb2lab(test)\n",
        "    l = lab[:,:,0]\n",
        "    L = gray2rgb(l)\n",
        "    L = L.reshape((1,IMG_SIZE,IMG_SIZE,3))\n",
        "    #print(L.shape)\n",
        "    ab = model.predict(L)\n",
        "    \n",
        "    #print(ab.shape)\n",
        "    ab = ab*128\n",
        "    cur = np.zeros((IMG_SIZE, IMG_SIZE, 3))\n",
        "    cur[:,:,0] = l\n",
        "    cur[:,:,1:] = ab\n",
        "    img = (lab2rgb(cur)*255).astype(np.uint8)\n",
        "    #dim = (400, 400)\n",
        "    #resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "    imsave(\"/content/drive/My Drive/Temp2/img\"+str(i)+\"c.jpg\", img)\n",
        "    i+=1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}